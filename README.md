# GIA AI Blog Backend

AI-powered fashion trend analysis backend for GIA Token. Scrapes social media platforms (Twitter/X, Instagram), processes content with NLP, clusters similar posts, and generates AI insights.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Social Media Sources     â”‚ â† Twitter API, Instagram Scraping
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scraping Layer           â”‚ â† Playwright, Axios, Cron Jobs
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Normalization Layer      â”‚ â† Text cleaning, NLP extraction
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Clustering Module        â”‚ â† Hashtag/keyword grouping
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI Insight Generator     â”‚ â† OpenAI GPT-4 integration
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MySQL Database           â”‚ â† Prisma ORM
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ REST API                 â”‚ â† Express.js endpoints
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+
- MySQL 8.0+
- Twitter API credentials
- OpenAI API key

### Installation

1. **Clone and install dependencies:**

```bash
cd Backend
npm install
```

2. **Configure environment:**

```bash
cp .env.example .env
# Edit .env with your credentials
```

3. **Setup database:**

```bash
npx prisma generate
npx prisma migrate dev
```

4. **Start development server:**

```bash
npm run dev
```

Server runs on `http://localhost:4000`

## ğŸ“¡ API Endpoints

### Authentication

#### Wallet Authentication (Primary)

```bash
# Get nonce for wallet signature
POST /api/v1/auth/wallet/nonce
Body: { "walletAddress": "0x..." }

# Login with wallet
POST /api/v1/auth/wallet/login
Body: { "walletAddress": "0x...", "signature": "0x..." }
```

#### Email Authentication (Optional)

```bash
# Register
POST /api/v1/auth/register
Body: { "email": "user@example.com", "password": "...", "username": "..." }

# Login
POST /api/v1/auth/login
Body: { "email": "user@example.com", "password": "..." }
```

### Trends

```bash
# Get all active trends
GET /api/v1/trends?limit=10&offset=0&sortBy=trendScore

# Get single trend with all posts
GET /api/v1/trends/:id
```

### Posts (Requires Auth)

```bash
# Like/unlike post
POST /api/v1/posts/:id/like
Headers: { "Authorization": "Bearer <token>" }

# Save/unsave post
POST /api/v1/posts/:id/save

# Add comment
POST /api/v1/posts/:id/comment
Body: { "content": "Great style!" }

# Get saved posts
GET /api/v1/posts/saved
```

### Admin (Requires Admin Role)

```bash
# Trigger manual scraping
POST /api/v1/admin/scrape/trigger

# Get system stats
GET /api/v1/admin/stats

# Get job history
GET /api/v1/admin/jobs
```

## ğŸ—„ï¸ Database Schema

### Key Tables

- **users** - User accounts (wallet + email auth)
- **scraped_posts** - Raw scraped data
- **normalized_posts** - Processed & scored posts
- **trend_clusters** - Grouped trends with AI insights
- **post_likes/comments/saves** - User interactions
- **scraping_jobs** - Job tracking

## ğŸ”„ Automated Pipeline

The scraping pipeline runs automatically every 6 hours (configurable):

1. **Scrape** posts from Twitter & Instagram
2. **Normalize** text, extract hashtags/keywords
3. **Cluster** similar posts together
4. **Generate** AI insights with OpenAI
5. **Calculate** trend scores & growth rates

Manually trigger: `POST /api/v1/admin/scrape/trigger`

## ğŸ› ï¸ Development

### Scripts

```bash
npm run dev          # Start dev server with hot reload
npm run build        # Compile TypeScript
npm run start        # Start production server
npm run prisma:studio # Open Prisma Studio (DB GUI)
```

### Project Structure

```
src/
â”œâ”€â”€ config/          # Configuration
â”œâ”€â”€ database/        # Prisma client
â”œâ”€â”€ jobs/            # Cron schedulers
â”œâ”€â”€ middleware/      # Express middleware
â”œâ”€â”€ routes/          # API routes
â”œâ”€â”€ services/        # Business logic
â”‚   â”œâ”€â”€ auth.service.ts
â”‚   â”œâ”€â”€ scraping.service.ts
â”‚   â”œâ”€â”€ normalization.service.ts
â”‚   â”œâ”€â”€ clustering.service.ts
â”‚   â””â”€â”€ ai-insight.service.ts
â”œâ”€â”€ sources/         # Social media scrapers
â”‚   â”œâ”€â”€ base.source.ts
â”‚   â”œâ”€â”€ twitter.source.ts
â”‚   â””â”€â”€ instagram.source.ts
â”œâ”€â”€ utils/           # Utilities
â””â”€â”€ server.ts        # Main entry point
```

## ğŸ” Environment Variables

See `.env.example` for all required variables:

- `DATABASE_URL` - MySQL connection string
- `JWT_SECRET` - JWT signing secret
- `OPENAI_API_KEY` - OpenAI API key
- `TWITTER_BEARER_TOKEN` - Twitter API token
- Social media credentials

## ğŸ“Š Monitoring

- Logs: `logs/app.log`
- Error logs: `logs/error.log`
- Job status: `GET /api/v1/admin/jobs`
- System stats: `GET /api/v1/admin/stats`

## ğŸš¨ Troubleshooting

### Database Connection Issues

```bash
# Check MySQL is running
mysql -u root -p

# Regenerate Prisma client
npx prisma generate
```

### Scraping Failures

- Check API credentials in `.env`
- Verify rate limits not exceeded
- Check logs in `logs/error.log`

### Instagram Scraping Issues

- Instagram requires browser automation
- May be blocked by rate limits
- Consider reducing scraping frequency

## ğŸ“ License

MIT

## ğŸ¤ Contributing

1. Create feature branch
2. Make changes
3. Add tests
4. Submit PR

## ğŸ“ Support

For issues, contact the GIA development team.
